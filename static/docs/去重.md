# 设计目的

下载文件之后储存下载记录；下载文件之前可以查询下载记录，判断文件是否重复。

除了考虑文件的 id，我还考虑了命名规则。但因为储存的命名规则并不是生成后的文件名，所以这不能达到区别文件名的目的。

在下载面板上增加设置项目：

- 启用去重  deduplication
- 去重策略？宽松 严格    dupliStrategy strict loose 
- 清空去重数据？ clearDownloadRecords

宽松策略是只通过 id 判断是否重复，严格策略是同时结合命名规则判断是否重复。


# 数据的存储方式：

## 数据库

去重数据（其实就是下载记录）单独存储在一个 IndexedDB 数据库中。

## 表

考虑到查询效率，这里做了分表。

根据 pixiv 作品 id 开头的数字，分成了 1-9 共 9 个表。当存储或查询时，根据作品 id 去对应的表里查询。

这样做是为了减少每个表里的数据量，这样在查询时可以避免不必要的查询，提高效率。

不过现实不会那么理想，因为数据的分布可能不是平均的。大家最常下载的应该是最近的作品，目前 pixiv 作品的 id 是 8000 w 多，所以表 8 可能存储的数据最多。

## 数据

每下载成功一个文件，添加它对应的下载记录。（下载失败的文件、跳过下载的文件不存储到下载记录里）

记录的数据如：

```
{
  id:'82666025_p0',
  n:'{p_title}/{id}-{user}-{tags_translate}'
}
```

`id` 字段是把作品 id 和作品类型连接起来了。

`n` 字段是命名规则。这里不保存实际生成的文件名，只保存命名规则。这是为了节约存储空间。

上面的例子中，假设一条数据占据的存储空间为 `60 B` 左右，那么 `1 GiB` 空间可以存储约 `1800 w` 条记录。已经很多了。

如果每个分表的数据最大量约为 1111w，那么大约有 `600 MiB` 的数据。

# IndexedDB 相关知识

## 额度控制

浏览器的本地存储的额度控制参考这里：

https://developer.mozilla.org/zh-CN/docs/Web/API/IndexedDB_API/Browser_storage_limits_and_eviction_criteria

根据这里面的说法，如果本地存储占据的硬盘空间达到上限，浏览器会依次清理掉最久没有被使用的源的数据。似乎一个域名就是一个源（子域名不同则视为不同的网站）。浏览器清理存储空间的时候是按源为单位的，所以如果清理到 pixiv.net 的话，其下所有数据库都会被删除。

## 何时会被清理

当用户清除浏览数据时，选择 **Cookie 及其它网站数据** 会清理本地存储，包括 localstorage、WebSQL、IndexedDB 等。